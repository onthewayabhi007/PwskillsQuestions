{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **Q1. What is Bayes' theorem?**\n",
    "# Bayes' theorem is a fundamental concept in probability theory and statistics that describes how to update the probability of a hypothesis or event based on new evidence. It provides a way to calculate conditional probabilities by incorporating prior knowledge and new observations. The theorem is named after the Reverend Thomas Bayes, who developed the basic idea in the 18th century.\n",
    "\n",
    "# **Q2. What is the formula for Bayes' theorem?**\n",
    "# Bayes' theorem is often stated in the following mathematical form:\n",
    "\n",
    "# \\[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} \\]\n",
    "\n",
    "# Where:\n",
    "# - \\( P(A|B) \\) is the probability of event A occurring given that event B has occurred (the posterior probability).\n",
    "# - \\( P(B|A) \\) is the probability of event B occurring given that event A has occurred (the likelihood).\n",
    "# - \\( P(A) \\) is the prior probability of event A occurring.\n",
    "# - \\( P(B) \\) is the probability of event B occurring.\n",
    "\n",
    "# **Q3. How is Bayes' theorem used in practice?**\n",
    "# Bayes' theorem is used in various fields, including statistics, machine learning, and artificial intelligence. It's applied in tasks like classification, spam filtering, medical diagnosis, and more. In practice, Bayes' theorem helps update probabilities as new evidence becomes available, making predictions and decisions more accurate.\n",
    "\n",
    "# **Q4. What is the relationship between Bayes' theorem and conditional probability?**\n",
    "# Bayes' theorem is a way to calculate conditional probabilities. Conditional probability is the probability of an event occurring given that another event has already occurred. Bayes' theorem provides a formal framework for updating conditional probabilities with new information.\n",
    "\n",
    "# **Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?**\n",
    "# Naive Bayes classifiers are a family of probabilistic classifiers that make strong independence assumptions between features. The choice of which type of Naive Bayes classifier to use (Gaussian, Multinomial, or Bernoulli) depends on the nature of your data:\n",
    "\n",
    "# - **Gaussian Naive Bayes:** This variant assumes that the features follow a Gaussian (normal) distribution. It's suitable for continuous numeric data.\n",
    "\n",
    "# - **Multinomial Naive Bayes:** This variant is used for discrete data, particularly when dealing with text classification or other types of data that can be represented as counts (e.g., word frequencies in documents).\n",
    "\n",
    "# - **Bernoulli Naive Bayes:** This variant is also used for discrete data, but it's specifically designed for binary features (either a feature is present or absent).\n",
    "\n",
    "# Choose the type of Naive Bayes classifier that best matches the distribution and nature of your data.\n",
    "\n",
    "# **Q6. Naive Bayes Classification:**\n",
    "# To predict the class of a new instance with features X1 = 3 and X2 = 4 using Naive Bayes, let's calculate the probabilities for both classes A and B:\n",
    "\n",
    "# Given that we have equal prior probabilities for each class (P(A) = P(B) = 0.5), we need to calculate \\( P(X1=3|A) \\), \\( P(X2=4|A) \\), \\( P(X1=3|B) \\), and \\( P(X2=4|B) \\) using the provided frequency table.\n",
    "\n",
    "# - \\( P(X1=3|A) = \\frac{4}{10} = 0.4 \\)\n",
    "# - \\( P(X2=4|A) = \\frac{3}{10} = 0.3 \\)\n",
    "# - \\( P(X1=3|B) = \\frac{1}{10} = 0.1 \\)\n",
    "# - \\( P(X2=4|B) = \\frac{3}{10} = 0.3 \\)\n",
    "\n",
    "# Now, we can apply Bayes' theorem to calculate the posterior probabilities:\n",
    "\n",
    "# For class A:\n",
    "# \\[ P(A|X1=3, X2=4) = \\frac{P(X1=3|A) \\cdot P(X2=4|A) \\cdot P(A)}{P(X1=3) \\cdot P(X2=4)} \\]\n",
    "\n",
    "# For class B:\n",
    "# \\[ P(B|X1=3, X2=4) = \\frac{P(X1=3|B) \\cdot P(X2=4|B) \\cdot P(B)}{P(X1=3) \\cdot P(X2=4)} \\]\n",
    "\n",
    "# Since we have equal prior probabilities and the denominators \\( P(X1=3) \\) and \\( P(X2=4) \\) are common for both calculations, we can compare the numerators \\( P(X1=3|A) \\cdot P(X2=4|A) \\) and \\( P(X1=3|B) \\cdot P(X2=4|B) \\):\n",
    "\n",
    "# - For class A: \\( 0.4 \\cdot 0.3 = 0.12 \\)\n",
    "# - For class B: \\( 0.1 \\cdot 0.3 = 0.03 \\)\n",
    "\n",
    "# Since \\( 0.12 > 0.03 \\), the Naive Bayes classifier would predict that the new instance with features \\( X1 = 3 \\) and \\( X2 = 4 \\) belongs to **Class A**."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
